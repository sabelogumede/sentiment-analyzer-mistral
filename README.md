### Sentiment Analyzer using Mistral via Ollama
This README provides a comprehensive overview of the Sentiment Analyzer project, including setup instructions, features, architecture, and more. It is designed to be user-friendly and informative for anyone looking to understand or contribute to the project.


```markdown
# ğŸ­ Sentiment Analyzer using Mistral via Ollama

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/Python-3.9%2B-blue)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116.1-green)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.48.0-orange)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama-Mistral-9cf)](https://ollama.com)

A **local, private, and explainable** sentiment analyzer that runs 100% on your machine â€” no internet, no data leaks.

Built with:
- ğŸ”¤ **FastAPI** â€“ Backend API
- ğŸ¨ **Streamlit** â€“ Frontend UI
- ğŸ§  **Mistral via Ollama** â€“ Local LLM for classification
- ğŸ’¬ **Explainable AI** â€“ Shows *why* a sentiment was assigned

Perfect for analyzing customer feedback, social media, emails, and more â€” all offline and secure.

---

## ğŸš€ Quick Start

### 1. Prerequisites

- [Python 3.9 or higher](https://www.python.org/downloads/)
- [Ollama](https://ollama.com/download) (to run Mistral locally)
- [Git](https://git-scm.com/downloads) (optional)

> âœ… Works on **Windows, macOS, and Linux**

---

### 2. Clone and Setup

```bash
# Clone the repo
git clone https://github.com/your-username/sentiment-analyzer-mistral.git
cd sentiment-analyzer-mistral

# Create virtual environment
python -m venv venv

# Activate it
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

### 3. Download the Mistral Model

```bash
# Start Ollama in the background
ollama serve
```

In another terminal:
```bash
ollama pull mistral
```

> ğŸ§  Downloads the Mistral model (~4.1GB). Only needed once.

---

### 4. Run the App

Open **two terminal windows**:

#### Terminal 1: Start FastAPI Backend
```bash
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

#### Terminal 2: Start Streamlit Frontend
```bash
streamlit run frontend/app.py
```

ğŸŒ Open the app at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ–¼ï¸ Screenshot

![Sentiment Analyzer Screenshot](screenshots/screenshot.png)

> ğŸ’¡ *Replace with your own screenshot! Save it in a `screenshots/` folder.*

---

## ğŸ§± Architecture

```
[User] 
   â†“
[Streamlit UI] â†’ HTTP POST â†’ [FastAPI Backend]
                                 â†“
                          [Ollama + Mistral]
                                 â†“
                      â† Sentiment + Explanation
```

- **Frontend**: `frontend/app.py` â€“ Streamlit interface with live feedback
- **Backend**: `backend/main.py` â€“ FastAPI with `/analyze` and `/explain` endpoints
- **Model**: Runs locally via Ollama (`mistral`)
- **Communication**: JSON over `localhost`

ğŸ” **No data leaves your machine. 100% private.**

---

## ğŸ› ï¸ Features

- âœ… Classify sentiment as **Positive**, **Negative**, or **Neutral**
- âœ… **Explain why** the sentiment was assigned (e.g., "Uses words like 'love' and 'perfect'")
- âœ… Live **character count**
- âœ… Warning for **non-text input** (e.g., numbers)
- âœ… Input validation & error handling
- âœ… Color-coded results (ğŸŸ¢/ğŸ”´/ğŸŸ¡)
- âœ… Clear input button
- âœ… Responsive and intuitive UI

---

## ğŸ“‚ Project Structure

```
sentiment-analyzer-mistral/
â”‚
â”œâ”€â”€ .gitignore               # Ignores venv, cache, IDE files
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py              # FastAPI backend with analysis + explanation
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py               # Streamlit frontend with explanation display
â”‚
â”œâ”€â”€ screenshots/             # (Optional) Add your app screenshots
â”‚   â””â”€â”€ screenshot.png
â”‚
â””â”€â”€ venv/                    # (Ignored) Virtual environment
```

---

## ğŸ“„ License

MIT License

Copyright (c) 2025 [Your Name]

Permission is hereby granted, free of charge, to any person obtaining a copy  
of this software and associated documentation files (the "Software"), to deal  
in the Software without restriction, including without limitation the rights  
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell  
copies of the Software, and to permit persons to whom the Software is  
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all  
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR  
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,  
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE  
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER  
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,  
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE  
SOFTWARE.

---

## ğŸ“Œ Tips for Users

- â³ **Analysis takes 5â€“60 seconds** â€” be patient! The model runs locally.
- ğŸ“ Best results with **natural language** (e.g., sentences with emotion).
- âš ï¸ Inputs with no letters (e.g., `123 456`) are flagged as low-confidence.
- ğŸ” The **"Why?"** section explains the reasoning behind the classification.
- ğŸ—‘ï¸ Use the **"Clear Input & Result"** button to start over.

---

## ğŸš§ Future Improvements

- ğŸ“ Support file uploads (TXT, CSV)
- ğŸ’¾ Export results as `.txt` or `.json`
- ğŸ”¤ Highlight key sentiment words in input
- ğŸ“Š Confidence score (e.g., "High", "Medium", "Low")
- ğŸ³ Docker support for one-click setup
- ğŸŒ Multi-language sentiment analysis

---

## ğŸ™Œ Made with â¤ï¸

By Sabelo Gumede â€“ for **private, powerful, and explainable AI**.

Have ideas or feedback? Open an issue or PR!

Keep building the future â€” locally. ğŸš€
```